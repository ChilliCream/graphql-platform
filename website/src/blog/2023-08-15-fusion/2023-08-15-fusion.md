---
path: "/blog/2023/03/15/graphql-fusion"
date: "2023-03-15"
title: "GraphQL-Fusion: An open approach towards distributed GraphQL"
description: "Together, we'll explore the new API feature coming with Banana Cake Pop 5 very soon."
tags: ["hotchocolate", "graphql", "federation", "fusion", "micro-services"]
author: Michael Staib
authorUrl: https://github.com/michaelstaib
authorImageUrl: https://avatars1.githubusercontent.com/u/9714350?s=100&v=4
---

## In the beginning

Right from the beginning, people saw the potential of GraphQL as a gateway technology. GraphQL promised a single integrated schema to the API consumer while offering the flexibility to leverage various technologies and services behind the scenes.

When GraphQL was introduced, front-end engineers where the first to glimpse the power of it and started wrapping their REST services with GraphQL. This made data fetching more efficient by aggregating data calls close to downstream services and rendered the data more accessible. The straightforward, human-understandable schema made it easier to trace relations and reason about data and its connections in an entirely new way.

GraphQL offered a way to model an interface to our core business domain that often diverged from the technical realities of the REST, gRPC, or other APIs behind it. It eliminated the complexity of knowing which micro-service would provide the necessary data or mutations for a particular use case. While micro-service or domain-service architectures provided technical means to scale more efficiently and align with organizational needs, GraphQL introduced simplicity with its unified schema approach.

From the outset, GraphQL server developers were challenged to find ways to simplify distributed GraphQL setups. Over time, we've witnessed the evolution of various methods, from schema stitching techniques to federated solutions like Apollo Federation. However, many of these either restrict users within a single-vendor ecosystem or, on the other end of the spectrum, are too rudimentary to cater to sophisticated enterprise requirements.

## Expectations

Our belief is that distributed GraphQL services — or composite GraphQL services — should not only be straightforward to set up but also seamlessly integrate with the diverse range of CI/CD tools, schema registries, composition utilities, and gateways that enterprises might prefer. The current landscape should not dictate the choice of tools but provide flexibility.

Up to this point, the GraphQL landscape has lacked an open specification tailored for distributed setups – a framework designed from the ground up for extensibility and integration with diverse toolchains. We envisioned a platform where tools from various vendors could effortlessly work in tandem, ensuring that developers and enterprises never feel constrained by their technical choices.

## Lets share and compete

Late last year ChilliCream and The Guild met in Paris and discussed their approaches twoards distributed GraphQL. It became very clear that both companies were solving similar problems and we decided to join forces on this project. ChilliCream would provide the initial work on the Fusion spec and implementation while The Guild would start specifying their work on Mash and Open API and help shape the initial Fusion spec.

Today, we are thrilled to unveil GraphQL-Fusion an open specification under the MIT license. This initiative empowers everyone to craft tools and solutions centered around distributed GraphQL services. Complementing this announcement, we're also introducing Hot Chocolate Fusion, an early implementation of the GraphQL-Fusion spec draft.

## A new way to distribute GraphQL schema components

GraphQL Fusion presents a fresh approach streamlining the complexities of assembling distributed schemas.

At its heart, GraphQL Fusion pivots around two foundational principles: schema composition and query planning.

But before delving into these concepts, it's essential to retrace our steps. Let's revisit the challenges that surfaced when people started their first tries with GraphQL as a Gateway constructing their GraphQL servers over REST APIs.

The ideal scenario is one where our teams operate autonomously, deploying updates at their pace. However, positioning a GraphQL server at the forefront as the Gateway introduced an unexpected bottleneck to the development flow. Suddenly, updating downstream APIs required updates to the central GraphQL server, leading to inevitable synchronization hurdles. Burdoning teams with higher maintanance and reduced felxibility.

While GraphQL schema stitching solutions simplified the composition of GraphQL Gateways they still suffered from the same coordination dilemma since the Gateway retained pivotal configuration logic. Federated GraphQL solutions emerged as a remedy, redistributing this configuration logic across subgraphs, thus enabling teams to work and release subgraphs autonomously.

Fusion represents a fully federated approach but also incorporates the capabilities of stitching soliutions to rewrite and transform subgraph schemas. Further, Fusion removes the requirement of subgraph protocols we see in many federated GraphQL solutions. This means you can use any GraphQL server as a Fusion subgraph and the capabilities of your subgraph withing a Fusion setup is defined by the GraphQL spec version your GraphQL server implements.

The Fusion schema composition aims to infer semantic meaning of schemas reducing annotation to the schema. Fusion schema composition recognises GraphQL best practices like the Relay patterns and recognises naming patterns and their semantics. Instead of treating fields and types bearing identical names as collisions, Fusion recognizes them as overlaps.

For clarity, consider the following GraphQL query type example:

```graphql
type Query {
  userByID(id: ID!): User
  productBySKU(sku: String!): Product
  articleBySlug(slug: String!): Article
}
```

In this example, fields follow the `{type}By{key}` naming convention:

- userByID for fetching users by ID
- productBySKU for retrieving products by SKU
- articleBySlug for obtaining articles by slug

Things we can fetch by one or multiple keys are entities to Fusion and allows the Fusion gateway during query planning to fill in data form various subgraphs. Fusion does not need to know their keys spelled out as this is infered from their resolver signature.

To elucidate, let's consider two subgraphs - one for product reviews and another for user data.

**Subgraph 1: Product Reviews**

```graphql
type Review {
  id: ID!
  body: String!
  product: Product!
  author: User!
}

type User {
  id: ID!
  name: String!
  reviews: [Review!]
}

type Product {
  sku: String!
  reviews: [Review!]
}

type Query {
  reviews: [Review!]
  reviewById(id: ID!): Review
  userById(id: ID!): User
  productBySKU(sku: String!): Product
}
```

**Subgraph 2: User Data**

```graphql
type User {
  id: ID!
  name: String!
  email: String!
}

type Query {
  userById(id: ID!): User
}
```

The outcome? An annotated Fusion graph document, which provides all the metadata for the Fusion gateway query planner.

**Composed Fusion Graph**

```graphql
type Review
  @variable(
    subgraph: "Reviews",
    name: "Review_id",
    select: "id")
  @resolver(
    subgraph: "Reviews"
    select: "{ reviewById(id: $Review_id) }"
    arguments: [{ name: "Review_id", type: "ID!" }]
  ) {
  id: ID!
    @source(subgraph: "Reviews")
  body: String!
    @source(subgraph: "Reviews")
  product: Product!
    @source(subgraph: "Reviews")
  author: User!
    @source(subgraph: "Reviews")
}

type User
  @variable(
    subgraph: "Reviews",
    name: "User_id",
    select: "id")
  @variable(
    subgraph: "Account",
    name: "User_id",
    select: "id")
  @resolver(
    subgraph: "Reviews"
    select: "{ userById(id: $id) }"
    arguments: [{ name: "User_id", type: "ID!" }]
  )
  @resolver(
    subgraph: "Account"
    select: "{ userById(id: $id) }"
    arguments: [{ name: "User_id", type: "ID!" }]
  ) {
  id: ID!
    @source(subgraph: "Reviews")
    @source(subgraph: "Account")
  name: String!
    @source(subgraph: "Reviews")
    @source(subgraph: "Account")
  email: String!
    @source(subgraph: "Account")
}

type Product
  @variable(
    subgraph: "Reviews",
    name: "Product_sku",
    select: "sku")
  @resolver(
    subgraph: "Reviews"
    select: "{ productBySKU(sku: $Product_sku) }"
    arguments: [{ name: "Product_sku", type: "String!" }]
  ) {
  sku: String!
    @source(subgraph: "Reviews")
  reviews: [Review!]
    @source(subgraph: "Reviews")
}

type Query {
  reviews: [Review!]
    @resolver(
      subgraph: "Reviews"
      select: "{ reviews }"
    )
  userById(id: ID!): User
    @resolver(
      subgraph: "Reviews"
      select: "{ userById(id: $id) }"
      arguments: [{ name: "id", type: "ID!" }]
    )
    @resolver(
      subgraph: "Account"
      select: "{ userById(id: $id) }"
      arguments: [{ name: "id", type: "ID!" }]
    )

  reviewById(id: ID!): Review
    @resolver(
      subgraph: "Reviews"
      select: "{ reviewById(id: $id) }"
      arguments: [{ name: "id", type: "ID!" }]
    )

  productBySKU(sku: String!): Product
    @resolver(
      subgraph: "Reviews"
      select: "{ productBySKU(id: $id) }"
      arguments: [{ name: "id", type: "ID!" }]
    )
}
```

## Query Planning and Optimizations

The above annotated schema document allows the Fusion gateway to efficiently plan data fetching from it's subgraphs.

When executing a query like following:

```graphql
query GetReviews {
  reviews {
    body
    author {
      name
      email
    }
  }
}
```

The query planner might produce two downstream queries:

**Query 1**

```graphql
query GetReviews_1 {
  reviews {
    body
    author {
      name
      __export__1 : id
    }
  }
}
```

**Query 2**

```graphql
query GetReviews_2($__export__1: ID!) {
  userById(id: $__export__1) {
    email
  }
}
```

While this does not seem quite efficient as we would have to do multiple subgraph requests the Fusion composition and query planner also understand batching fields and how to integrate them into the query planning process. If we simply introduced the following root field to our accounts subgraph and recompose:

```graphql
extend type Query {
  usersById(ids: [ID!]!): [User!]
}
```

The composition would add an additional batching resolver to the `User` type:

```graphql
extend type User
  @resolver(
    subgraph: "Account",
    select: "{ usersById(ids: $User_Id) }",
    arguments: [ { name: "User_Id", type: "[ID!]!" } ],
    kind: "BATCH_BY_KEY"
    ) {
}
```

With this new field in place the query planner can now prioritize batch resolvers whenever we branch of a reqest in a list context even if that list context spreads multiple levels.

**Query 1**

```graphql
query GetReviews_1 {
  reviews {
    body
    author {
      name
      __export__1 : id
    }
  }
}
```

**Query 2**

```graphql
query GetReviews_2($__export__1: [ID!]!) {
  usersById(id: $__export__1) {
    email
  }
}
```

## Relay

The schema composition can also introduce aspects such as Relay conventions to your Gateway schema, even if they aren't implemented in your subgraphs.

Alternatively, if your subgraphs implement the Relay conventions, such as the Global object convention, the schema composition will detect this and incorporate it into the Fusion Graph document. This can optimize your query planning, for example, by utilizing the node field.

```graphql
extend type User
  @resolver(
    subgraph: "User",
    select: "{ node(id: $User_id) { ... on User { ... User } } }",
    arguments: [ { name: "User_id", type: "ID!" } ])
  @resolver(
    subgraph: "User",
    select: "{ nodes(ids: $User_id) { ... on User { ... User } } }",
    arguments: [ { name: "User_id", type: "[ID!]!" } ],
    kind: "BATCH_BY_KEY") {
}
```

While using the `node` fields to fetch entity data is straightforward for exposing the `node` fields to the Gateway, we found it necessary to equip the Fusion gateway with data sharding capabilities. This is essentially the ability to dispatch a query at runtime to a subgraph based on user-provided data. This can be applied to simple tasks like the node field, but can also be harnessed to isolate data partitions by region or any other discriminant you desire.

## Going Further

While the subgraph inference is quite powerfull there are a lot of cases where its more powerful and precise to declare semntics of a schema.

Let's say the batching field we introduced did not follow the conventions our other fields follow.

```graphql
extend type Query {
  users(ids: [ID!]!): [User!]
}
```

In this case we cannot just guess what `ids` is, for all we know it could be the ids or products a user is associated to. This is where we can use the fusion subgraph directives to bring meaning to the schema.

```graphql
extend type Query {
  users(ids: [ID!]! @is(field: "id")): [User!]
}
```

The `@is` directive allows us to specify that the argument on that field is semantically the same as the output field `id`. Since `ids` is a list and it returns a list of users we can now infer form that, that we can pass in a collection of `ids` and get out a list of `User` objects.

## Requirements

We can also express requirements for our resolvers. Requirements are things we need from somewhere else befor we can execute something.

Let's say we have the following schema:

```graphql
type Product {
  sku: String!
  name: String!
  dimension: ProductDimension
}
```

Also let's say we have a subgraph that is able to calculate a shipping estimate for a product.

```graphql
type Product {
  estimateShipping(zip: String!, width: Float!, height: Float!): Int!
}
```

The arguments for `weight` and `height` already exist in the product dimension object and so could be omitted from the public gateway schema as the query planner could resolve this requirement.

```graphql
type Product {
  estimateShipping(
    zip: String!,
    width: Float! @require(field: "dimension { width }"),
    height: Float! @require(field: "dimension { height }")) : Int!
}
```

We also could design that differently and introduce a input to our subgraph.

```graphql
input ProductDimensionInput {
  width: Float!,
  height: Float!
}

type Product {
  estimateShipping(
    zip: String!,
    dimension: ProductDimensionInput! @require(field: "dimension")): Int!
}
```

The query planner would in this case select all necessary data to fulfill the input. The result form the schema composition would be the same and we would endup with the following public `Product` type.

```graphql
type Product {
  sku: String!
  name: String!
  dimension: ProductDimension
  estimateShipping(zip: String!): Int!
}
```

Again, this brings actual clarity to your subgraph as the field is very clear what it needs. Each argument essentially represents a requirement, some of them have defaults and are provided by the consmer, others are internally resolved from the context.

## Reshaping things

But lets think about the shipping service again.

```graphql
type Product {
  estimateShipping(zip: String!, width: Float!, height: Float!): Int!
}
```

It actually does not necessaryly make sense to have this product stub object. In this case we could also have a simple root field representing this calculation field.

```graphql
type Query {
  estimateShipping(zip: String!, width: Float!, height: Float!): Int!
}
```

In the case our subgraph is isolated and does not fully integrate with our though for model that we want to expose on the gateway we can also reshape it.

All the annotations can be put into separate graphql document providing the extending metadata. First lets make the whole query type private, we actually do not want to include anything by default form this subgraph.

```graphql
extend type Query @private
```

Next, we introduce some product metadata.

```graphql
extend type Product {
  estimateShipping(
    zip: String!,
    width: Float! @require(field: "dimension { width }"),
    height: Float! @require(field: "dimension { height }")) : Int!
}

extend type Query @private
```

Last, we want to declare how estimate wires up to our internal `Query` type.

```graphql
extend type Product {
  estimateShipping(
    zip: String!,
    width: Float! @require(field: "dimension { width }"),
    height: Float! @require(field: "dimension { height }")) : Int!
        @resolve
}

extend type Query @private
```

Since the fiel and arguments 100% match between the `Query` type and the `Product` type extension we just need to put resolve on. But let image we call it `calculateShipping` on the product type. In this case we would need to become more explicit.

```graphql
extend type Product {
  calculateShipping(
    zip: String!,
    width: Float! @require(field: "dimension { width }"),
    height: Float! @require(field: "dimension { height }")) : Int!
        @resolve(select: "estimateShipping")
}

extend type Query @private
```

Again, arguments match so we do not need to map them, but we could. Each argument would become an implicit variable in this case.

```graphql
extend type Product {
  calculateShipping(
    zip: String!,
    width: Float! @require(field: "dimension { width }"),
    height: Float! @require(field: "dimension { height }")) : Int!
        @resolve(select: "estimateShipping(zip: $zip)")
}

extend type Query @private
```

Arguments that you do not map are again infered, allowing you to always just specify the minimum. Since Fusion compiles the Fusion Graph at build time this is fine as the schema composition will always tell you what is missing and exactly in which file you have to specify more information for the composition and query planner to work.

Let's move on from the requirements case and dig a bit deeper into the type reshaping capabilities. Often when we build our silos we do not have all the stub types in there as well. It sometimes would be tedious to always have them around. Think of the review service.

```graphql
type Review {
  id: ID!
  body: String!
  product: Product!
  author: User!
}
```

This `Product` type is essentiall just the `sku` of the product. People are more tempted to create something like this in  the subgraph schema since its just less clutter.

```graphql
type Review {
  id: ID!
  body: String!
  productSKU: String!
  author: User!
}
```

With Fusion you can provide us some metadata in the schema extension file and we will ensure that the references are introduced on our public exposed gateway schema.

```graphql
extend type Review {
  productSKU: String! @is(coordinate: "Product.sku") @private
  product: Product! @resolve
}
```

By declaring the semantic of the field `productSKU` we are able to infer a way to resolve product by using one of the ways that exist to fetch a `Product` entity. Again, if there was no way to resolve it we will give you a composition error that tells you on which subgraphs you could or should introduce `Query` fields to reslve this entity.

But in many cases we want to connect our types from both sides.

```graphql
extend type Product {
  reviews: [Review!] @resolve
}

extend type Review {
  productSKU: String! @is(coordinate: "Product.sku") @private
  product: Product! @resolve
}
```

For this to work we would need to introduce a `reviewsBySKU` to our reviews subgraph. But we will be told by our schema composition if it were missing on our subgraph.

Like with our case for estimate shipping we can be more or less explicit with our `@resolve` directive.

```graphql
extend type Product {
  reviews: [Review!]
    @resolve(select: "reviewsBySku(sku: $sku)")
}
```

Since `sku` is available on product it is automatically a variable avilable to inject. But because of collisions with field arguments or if the actual sku is not directly on the product type we also could explicitly declare the variable.

```graphql
extend type Product {
  reviews: [Review!]
    @declare(variable: "sku" select: "someOtherField { sku }")
    @resolve(select: "reviewsBySku(sku: $sku)")
}
```

> The `select` argument represents a field selection or selection set syntax and also allows for more complex query constructs that refer to GraphQL query files using fragments and other query constructs. For this introduction we keep it simple.

When I said in the beginning that Fusion lends concepts from both schema stitching and federation approaches than its this kind of flexibility that I mean. You can build your graph in a federated structure and you will in most cases not need to declare anything to the composition as it can be inferred, but you can become very explicit with hints or even with expliciter with ther `@resolve` directive.

## Open Telemetry for federated Tracing

This brings me to another aspect of Fusion: telemetry. While the GraphQL-Fusion spec isn't primarily concerned with tracing itself, we've decided to leverage OpenTelemetry for the Hot Chocolate Fusion Gateway implementation. We're currently working to establish a more precise semantic convention for GraphQL in collaboration with the OpenTelemetry community. This effort aims to enable standard GraphQL servers to use OpenTelemetry to expose the intricate processes that occur when a GraphQL server handles a request. These traces, correlated from the Gateway to the subgraph, allow any vendor to digest tracing events and provide profound insights into where performance bottlenecks exist in your distributed system.

When combined with the explicit GraphQL subgraphs, which use the _entities field to retrieve data from subgraphs, it becomes increasingly clear where optimization opportunities lie. The best part? There's no need for any specialized approaches—it's as straightforward as crafting a conventional resolver. With the release of Banana Cake Pop version 9, we're introducing our revamped query plan viewer. This tool signifies our initial step towards integrating telemetry data from GraphQL Fusion, aiming to provide comprehensive insights into the operations of your distributed GraphQL setup. However, thanks to the open nature of the GraphQL-Fusion spec and the OpenTelemetry definitions, you're not confined to our tools—alternatives like The Guild's Hive are also available.

[Screen Shot BCP 9]

## CI/CD integrations from the Start

We considered CI/CD from the start when conceptualizing Fusion and structured it in a way that you can easily integrate your own solution. Moreover, we have supported you right from the beginning with Banana Cake Pop, which provides a schema registry, easy rollbacks of changes introduced by your subgraphs, and deployment pipeline synchronization. But the core principle is that this is open and built into the GraphQL-Fusion spec. To provide tooling a single file containing all the information needed for gateway configuration and even space for gateway-specific features, we've adopted the Open Packaging Convention as a container for the GraphQL-Fusion Configuration.

The Open Packaging Convention is an open standard provided by Microsoft, used for everything from Word Documents to VSCode extension packages. Simply put, think of it as a ZIP container with metadata and relations between its artifacts. The GraphQL-Fusion convention contains the mandatory Fusion Graph document. This document is all that's needed to run and configure a Gateway implementing the core specification.

Additionally, it contains all subgraph schema documents and the publicly exposed Gateway schema. Having all these artifacts in one place gives us a single artifact that we can pass from the schema composition in a CI/CD pipeline to the schema registry, and from there to the gateway. We have customers already using this with their custom solutions for distributing the configuration from their deployment pipeline to their Gateway or by using our Cloud Services. This ensures that neither your consumers nor your gateway experiences any interruptions.

Besides these standard components, it also allows Gateway implementers to store custom configurations to specify GraphQL WAF settings and more.

[SCHEMA of the Fusion config]

## Conclusion

We are still working on GraphQL-Fusion, but you can try it today with the Hot Chocolate Fusion Gateway. We plan to release the GraphQL-Fusion spec as it matures later this year under the MIT license. While the current iterations are primarily concerned with GraphQL, The Guild has begun specifying the Open API to GraphQL transformation they've developed in Mesh, and we'll integrate this as it becomes available. Additionally, there's much more from the query plan engine and composition we're eager to showcase, such as field requirements, transforming subgraphs to better integrate into your overall graph, even manual annotations instead of inference, and the fact that you can take any Apollo Subgraph and seamlessly incorporate it into the schema composition. This allows it to work in orchestration with other non-Apollo Federation subgraphs. Currently, we're all hands on deck working on a step-by-step tutorial, which will guide you through every detail, from a simple setup to a full-fledged enterprise solution. This includes features like schema change tracking and build-time errors that inform you of potential issues even before your first subgraph commit.
